# -*- coding: utf-8 -*-
"""part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eHuLIN8JnU3CHTB8iQmMyu0I0PQZAgaG
"""

import numpy as np
import pandas as pd

from ucimlrepo import fetch_ucirepo

# fetch dataset
student_performance = fetch_ucirepo(id=320)

# data (as pandas dataframes)
X = student_performance.data.features
y = student_performance.data.targets

# metadata
print(student_performance.metadata)

# variable information
print(student_performance.variables)

import matplotlib.pyplot as plt
import itertools

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df = pd.concat([X, y["G3"]], axis=1)
print("DF shape:", df.shape)

# Preprocessing steps
# Check for null values
print(df.isnull().sum())
df = df.dropna()

# Remove duplicate rows
duplicates = df.duplicated().sum()
print("Duplicate rows:", duplicates)
df = df.drop_duplicates()

# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

# Convert categorical to numerical using simple encoding
for col in categorical_cols:
    df[col] = pd.Categorical(df[col]).codes

# Separate features and target
target_col = 'G3'
X = df.drop(target_col, axis=1).values.astype(float)
y = df[target_col].values.astype(float)

# 80/20 split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print(f"\nTrain set: {len(X_train)}")
print(f"Test set: {len(X_test)}")


# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)
print("Features standardized")

def compute_mse(y_true, y_pred):
    return np.mean((y_pred - y_true)**2)

def compute_rmse(y_true, y_pred):
    return np.sqrt(compute_mse(y_true, y_pred))

def compute_mae(y_true, y_pred):
    return np.mean(np.abs(y_pred - y_true))

def compute_r2(y_true, y_pred):
    ss_res = np.sum((y_true - y_pred)**2)
    ss_tot = np.sum((y_true - np.mean(y_true))**2)
    return 1.0 - (ss_res / ss_tot if ss_tot != 0 else 0.0)

def explained_variance(y_true, y_pred):
    var_y = np.var(y_true)
    return 1.0 - (np.var(y_true - y_pred) / var_y if var_y != 0 else 0.0)

def gradient_descent(X, y, learning_rate, max_iter):
    m = len(y)  # number of samples
    n = X.shape[1]  # number of features

    # Initialize weights randomly
    weights = np.random.randn(n) * 0.01

    cost_history = []

    for i in range(max_iter):
        # Compute predictions: y_pred = X * w
        predictions = X.dot(weights)

        # Compute error
        error = predictions - y

        # Compute gradient: gradient = (1/m) * X^T * error
        gradient = (1/m) * X.T.dot(error)

        # Update weights: w = w - learning_rate * gradient
        weights = weights - learning_rate * gradient

        # Calculate and store cost
        cost = (1/(2*m)) * np.sum(error**2)
        cost_history.append(cost)

        # Print progress
        if i % 1000 == 0:
            print(f"Iteration {i}: Cost = {cost:.4f}")

    return weights, cost_history

def predict(X, weights):
    return X.dot(weights)

# Add bias term
X_train_bias = np.c_[np.ones(X_train.shape[0]), X_train]
X_test_bias  = np.c_[np.ones(X_test.shape[0]),  X_test]

# Hyperparameters to test
learning_rates = [0.0005, 0.001, 0.005, 0.01]
max_iters = [1000, 3000, 6000, 10000]

results = []
best = {"test_mse": float("inf"), "params": None, "weights": None, "cost_history": None}

for lr, iters in itertools.product(learning_rates, max_iters):
    weights, cost_history = gradient_descent(X_train_bias, y_train, lr, iters)

    train_pred = predict(X_train_bias, weights)
    test_pred  = predict(X_test_bias,  weights)

    train_mse = compute_mse(y_train, train_pred)
    test_mse  = compute_mse(y_test,  test_pred)

    train_rmse = compute_rmse(y_train, train_pred)
    test_rmse  = compute_rmse(y_test,  test_pred)

    train_mae = compute_mae(y_train, train_pred)
    test_mae  = compute_mae(y_test,  test_pred)

    train_r2 = compute_r2(y_train, train_pred)
    test_r2  = compute_r2(y_test,  test_pred)

    train_ev = explained_variance(y_train, train_pred)
    test_ev  = explained_variance(y_test,  test_pred)

    results.append({
        "learning_rate": lr,
        "max_iter": iters,
        "train_mse": train_mse,
        "test_mse": test_mse,
        "train_rmse": train_rmse,
        "test_rmse": test_rmse,
        "train_mae": train_mae,
        "test_mae": test_mae,
        "train_r2": train_r2,
        "test_r2": test_r2,
        "train_explained_variance": train_ev,
        "test_explained_variance": test_ev,
        "final_cost": cost_history[-1] if len(cost_history) else np.nan
    })

    if test_mse < best["test_mse"]:
        best["test_mse"] = test_mse
        best["params"] = (lr, iters)
        best["weights"] = weights
        best["cost_history"] = cost_history

# Save log to CSV
results_df = pd.DataFrame(results).sort_values("test_mse").reset_index(drop=True)
results_df.to_csv("gd_trials_log.csv", index=False)

print("Saved hyperparameter trials log to: gd_trials_log.csv")
print("Best params (lr, max_iter):", best["params"])
print("Best test MSE:", best["test_mse"])

import seaborn as sns
# Visualizing plots
best_weights = best["weights"]
best_cost_history = best["cost_history"]

# Predictions using best model
best_train_pred = predict(X_train_bias, best_weights)
best_test_pred  = predict(X_test_bias,  best_weights)

# Convert stored cost J = (1/(2m)) * sum(error^2) into true MSE = (1/m) * sum(error^2)
mse_history = [2*c for c in best_cost_history]

# MSE vs Iterations
plt.figure()
plt.plot(mse_history)
plt.xlabel("Iteration")
plt.ylabel("MSE")
plt.title(f"MSE vs Iterations (Best: lr={best['params'][0]}, iters={best['params'][1]})")
plt.show()

# Actual vs Predicted (Test Set)
plt.figure()
plt.scatter(y_test, best_test_pred)
plt.xlabel("Actual G3")
plt.ylabel("Predicted G3")
plt.title("Actual vs Predicted (Test Set)")
plt.show()

# Residuals vs Predicted (Test Set)
residuals = y_test - best_test_pred
plt.figure()
plt.scatter(best_test_pred, residuals)
plt.xlabel("Predicted G3")
plt.ylabel("Residual (Actual - Predicted)")
plt.title("Residuals vs Predicted (Test Set)")
plt.axhline(0)
plt.show()

# Hyperparameter tuning heatmap (Test MSE)
heatmap_data = results_df.pivot(index="learning_rate", columns="max_iter", values="test_mse")

plt.figure(figsize=(8, 6))
sns.heatmap(heatmap_data, annot=True, fmt=".2f")
plt.xlabel("Max Iterations")
plt.ylabel("Learning Rate")
plt.title("Hyperparameter Tuning Heatmap (Test MSE)")
plt.show()